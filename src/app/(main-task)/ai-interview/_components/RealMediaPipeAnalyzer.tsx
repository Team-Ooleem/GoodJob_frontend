'use client';

interface DetectionResult {
    type: 'posture' | 'eye_contact' | 'smile' | 'gesture' | 'confidence' | 'attention' | 'stress';
    message: string;
    level: 'good' | 'warning' | 'excellent';
    confidence: number;
    landmarks: any;
    metrics: any;
}

export class RealMediaPipeAnalyzer {
    private videoRef: React.RefObject<HTMLVideoElement>;
    private canvasRef: React.RefObject<HTMLCanvasElement>;
    private onDetection: (data: DetectionResult) => void;
    private isAnalyzing = false;
    private animationFrameId: number | null = null;
    private lastLogTime = 0;
    private logInterval = 10000; // 10ì´ˆë§ˆë‹¤ ë¶„ì„ ê²°ê³¼ ë¡œê·¸ ì¶œë ¥
    private analysisInterval = 5000; // 5ì´ˆë§ˆë‹¤ ë¶„ì„ ì‹¤í–‰
    private lastAnalysisTime = 0;

    // MediaPipe Tasks Vision ëª¨ë¸ë“¤
    private faceLandmarker: any = null;
    private vision: any = null;
    private isInitialized = false; // ì´ˆê¸°í™” ìƒíƒœ ì¶”ì 

    // ë¶„ì„ ê²°ê³¼ ì €ì¥
    private lastFaceResults: any = null;
    private lastDetectionTime = 0;
    private lastAnalysisLogTime = 0;
    private hasLoggedInitialData = false; // ìµœì´ˆ ì›¹ìº  ë°ì´í„° ë¡œê·¸ ì—¬ë¶€

    constructor(
        videoRef: React.RefObject<HTMLVideoElement>,
        canvasRef: React.RefObject<HTMLCanvasElement>,
        onDetection: (data: DetectionResult) => void,
    ) {
        this.videoRef = videoRef;
        this.canvasRef = canvasRef;
        this.onDetection = onDetection;
    }

    // MediaPipe Tasks Vision ëª¨ë¸ ì´ˆê¸°í™”
    public async initializeModels() {
        // ì´ë¯¸ ì´ˆê¸°í™”ë˜ì—ˆë‹¤ë©´ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
        if (this.isInitialized) {
            console.log('âš ï¸ MediaPipe ëª¨ë¸ì´ ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¤‘ë³µ ì‹¤í–‰ì„ ë°©ì§€í•©ë‹ˆë‹¤.');
            return;
        }

        try {
            console.log('ğŸš€ MediaPipe Tasks Vision ëª¨ë¸ ì´ˆê¸°í™” ì‹œì‘...');

            // ğŸ”‘ SSR íšŒí”¼: ëŸ°íƒ€ì„ì—ì„œë§Œ ë™ì  import
            const { FaceLandmarker, FilesetResolver } = await import('@mediapipe/tasks-vision');
            console.log('ğŸ“¦ MediaPipe Tasks Vision ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì™„ë£Œ');

            // ğŸ”‘ WASM ìì‚° ê²½ë¡œ (ì •ì  í´ë”ì— ë³µì‚¬ëœ íŒŒì¼ë“¤)
            console.log('ğŸ”§ WASM íŒŒì¼ì…‹ ì´ˆê¸°í™” ì¤‘...');
            this.vision = await FilesetResolver.forVisionTasks('/mediapipe/wasm');
            console.log('âœ… WASM íŒŒì¼ì…‹ ì´ˆê¸°í™” ì™„ë£Œ');

            // Face Landmarker ëª¨ë¸ ì´ˆê¸°í™”
            console.log('ğŸ‘ï¸ Face Landmarker ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...');
            this.faceLandmarker = await FaceLandmarker.createFromOptions(this.vision, {
                baseOptions: {
                    modelAssetPath: '/mediapipe/face_landmarker.task', // public/mediapipe ì— ë°°ì¹˜
                },
                outputFaceBlendshapes: true,
                outputFacialTransformationMatrixes: false,
                runningMode: 'VIDEO',
                numFaces: 1,
            });

            this.isInitialized = true; // ì´ˆê¸°í™” ì™„ë£Œ í‘œì‹œ
            console.log('âœ… MediaPipe Tasks Vision ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ');
        } catch (error) {
            console.error('âŒ MediaPipe Tasks Vision ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
            this.isInitialized = false; // ì‹¤íŒ¨ ì‹œ ì´ˆê¸°í™” ìƒíƒœ ë¦¬ì…‹
            throw error;
        }
    }

    // Face Landmarker ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬
    private analyzeFaceResults(results: any) {
        // 10ì´ˆë§ˆë‹¤ë§Œ ë¶„ì„ ê²°ê³¼ ë¡œê·¸ ì¶œë ¥
        const currentTime = Date.now();
        if (currentTime - this.lastAnalysisLogTime >= this.logInterval) {
            console.log('ğŸ‘ï¸ Face Landmarker ë¶„ì„ ê²°ê³¼ (10ì´ˆë§ˆë‹¤):', {
                timestamp: new Date().toISOString(),
                hasLandmarks: !!results.faceLandmarks,
                facesCount: results.faceLandmarks?.length || 0,
                hasBlendshapes: !!results.faceBlendshapes,
                blendshapesCount: results.faceBlendshapes?.length || 0,
                firstFaceLandmarks: results.faceLandmarks?.[0]
                    ? results.faceLandmarks[0].slice(0, 5)
                    : null,
            });
            this.lastAnalysisLogTime = currentTime;
        }

        // ğŸ” ì›ë³¸ MediaPipe ë°ì´í„° ë¡œê·¸ ì¶œë ¥ (5ì´ˆë§ˆë‹¤)
        if (currentTime - this.lastAnalysisLogTime >= this.logInterval) {
            console.log('ğŸ“Š MediaPipe ì›ë³¸ ë°ì´í„° (10ì´ˆë§ˆë‹¤):', {
                timestamp: new Date().toISOString(),
                rawResults: {
                    faceLandmarks: results.faceLandmarks?.[0]
                        ? {
                              count: results.faceLandmarks[0].length,
                              sample: results.faceLandmarks[0].slice(0, 10), // ì²˜ìŒ 10ê°œ ëœë“œë§ˆí¬
                              eyeLandmarks: {
                                  leftEye: results.faceLandmarks[0][159], // ì™¼ìª½ ëˆˆ ì¤‘ì‹¬
                                  rightEye: results.faceLandmarks[0][386], // ì˜¤ë¥¸ìª½ ëˆˆ ì¤‘ì‹¬
                                  noseTip: results.faceLandmarks[0][1], // ì½” ë
                              },
                          }
                        : null,
                    faceBlendshapes: results.faceBlendshapes?.[0]
                        ? {
                              categories:
                                  results.faceBlendshapes[0].categories?.map((cat: any) => ({
                                      categoryName: cat.categoryName,
                                      score: cat.score,
                                  })) || [],
                          }
                        : null,
                },
            });
        }

        if (!results.faceLandmarks || results.faceLandmarks.length === 0) {
            return;
        }

        const faceLandmarks = results.faceLandmarks[0];
        const faceBlendshapes = results.faceBlendshapes?.[0];

        // ì‹œì„  ë¶„ì„ (ëˆˆ ëœë“œë§ˆí¬ë“¤)
        // MediaPipe Face Landmarkerì˜ 468ê°œ ëœë“œë§ˆí¬ ì¤‘ ëˆˆ ê´€ë ¨ ëœë“œë§ˆí¬ë“¤
        const leftEyeCenter = faceLandmarks[159]; // ì™¼ìª½ ëˆˆ ì¤‘ì‹¬
        const rightEyeCenter = faceLandmarks[386]; // ì˜¤ë¥¸ìª½ ëˆˆ ì¤‘ì‹¬
        const noseTip = faceLandmarks[1]; // ì½” ë

        const eyeContactScore = 1 - Math.abs((leftEyeCenter.x + rightEyeCenter.x) / 2 - 0.5);

        // ë©´ì ‘ìš© ì¢…í•© í‘œì • ë¶„ì„ (Blendshapes ì‚¬ìš©)
        const interviewMetrics = this.calculateInterviewMetrics(faceBlendshapes, faceLandmarks);

        // ğŸ” ê°€ê³µëœ ë©”íŠ¸ë¦­ ë°ì´í„° ë¡œê·¸ ì¶œë ¥ (10ì´ˆë§ˆë‹¤)
        const metricsLogTime = Date.now();
        if (metricsLogTime - this.lastAnalysisLogTime >= this.logInterval) {
            console.log('ğŸ¯ ê°€ê³µëœ ë©´ì ‘ ë©”íŠ¸ë¦­ ë°ì´í„° (10ì´ˆë§ˆë‹¤):', {
                timestamp: new Date().toISOString(),
                processedMetrics: {
                    confidence: interviewMetrics.confidence,
                    stress: interviewMetrics.stress,
                    attention: interviewMetrics.attention,
                    engagement: interviewMetrics.engagement,
                    eyeContact: interviewMetrics.eyeContact,
                    smile: interviewMetrics.smile,
                    nervousness: interviewMetrics.nervousness,
                    composure: interviewMetrics.composure,
                },
                rawLandmarks: {
                    leftEye: { x: leftEyeCenter.x, y: leftEyeCenter.y, z: leftEyeCenter.z },
                    rightEye: { x: rightEyeCenter.x, y: rightEyeCenter.y, z: rightEyeCenter.z },
                    nose: { x: noseTip.x, y: noseTip.y, z: noseTip.z },
                },
            });
        }

        // ê° ë©”íŠ¸ë¦­ì— ëŒ€í•œ í”¼ë“œë°± ìƒì„±
        this.generateInterviewFeedback(interviewMetrics, leftEyeCenter, rightEyeCenter, noseTip);
    }

    // ë©´ì ‘ìš© ë©”íŠ¸ë¦­ ê³„ì‚°
    private calculateInterviewMetrics(faceBlendshapes: any, faceLandmarks: any) {
        const metrics = {
            confidence: 0,
            stress: 0,
            attention: 0,
            engagement: 0,
            eyeContact: 0,
            smile: 0,
            nervousness: 0,
            composure: 0,
        };

        if (!faceBlendshapes?.categories) return metrics;

        const blendshapes = faceBlendshapes.categories;

        // ìì‹ ê° ì§€í‘œ (ë¯¸ì†Œ, ëˆˆì¹ ìœ„ì¹˜, í„± ê°ë„)
        const smileLeft =
            blendshapes.find((cat: any) => cat.categoryName === 'mouthSmileLeft')?.score || 0;
        const smileRight =
            blendshapes.find((cat: any) => cat.categoryName === 'mouthSmileRight')?.score || 0;
        const browInnerUp =
            blendshapes.find((cat: any) => cat.categoryName === 'browInnerUp')?.score || 0;
        const browOuterUpLeft =
            blendshapes.find((cat: any) => cat.categoryName === 'browOuterUpLeft')?.score || 0;
        const browOuterUpRight =
            blendshapes.find((cat: any) => cat.categoryName === 'browOuterUpRight')?.score || 0;

        metrics.smile = (smileLeft + smileRight) / 2;
        metrics.confidence =
            metrics.smile * 0.4 +
            (browOuterUpLeft + browOuterUpRight) * 0.3 +
            (1 - browInnerUp) * 0.3;

        // ìŠ¤íŠ¸ë ˆìŠ¤/ê¸´ì¥ ì§€í‘œ (ëˆˆì¹ ì°Œí‘¸ë¦¼, ì… ì••ë°•, í„± ê¸´ì¥)
        const browDownLeft =
            blendshapes.find((cat: any) => cat.categoryName === 'browDownLeft')?.score || 0;
        const browDownRight =
            blendshapes.find((cat: any) => cat.categoryName === 'browDownRight')?.score || 0;
        const mouthPressLeft =
            blendshapes.find((cat: any) => cat.categoryName === 'mouthPressLeft')?.score || 0;
        const mouthPressRight =
            blendshapes.find((cat: any) => cat.categoryName === 'mouthPressRight')?.score || 0;
        const jawOpen = blendshapes.find((cat: any) => cat.categoryName === 'jawOpen')?.score || 0;

        metrics.stress = (browDownLeft + browDownRight + mouthPressLeft + mouthPressRight) / 4;
        metrics.nervousness = metrics.stress;

        // ì§‘ì¤‘ë„/ì£¼ì˜ë ¥ ì§€í‘œ (ëˆˆ ê¹œë¹¡ì„, ì‹œì„ )
        const eyeBlinkLeft =
            blendshapes.find((cat: any) => cat.categoryName === 'eyeBlinkLeft')?.score || 0;
        const eyeBlinkRight =
            blendshapes.find((cat: any) => cat.categoryName === 'eyeBlinkRight')?.score || 0;
        const eyeLookDownLeft =
            blendshapes.find((cat: any) => cat.categoryName === 'eyeLookDownLeft')?.score || 0;
        const eyeLookDownRight =
            blendshapes.find((cat: any) => cat.categoryName === 'eyeLookDownRight')?.score || 0;

        metrics.attention = 1 - (eyeBlinkLeft + eyeBlinkRight) / 2;
        metrics.eyeContact = 1 - (eyeLookDownLeft + eyeLookDownRight) / 2;

        // ì°¸ì—¬ë„/ì ê·¹ì„± ì§€í‘œ (ì „ì²´ì ì¸ í‘œì • í™œë™ì„±)
        const cheekPuff =
            blendshapes.find((cat: any) => cat.categoryName === 'cheekPuff')?.score || 0;
        const mouthFunnel =
            blendshapes.find((cat: any) => cat.categoryName === 'mouthFunnel')?.score || 0;

        metrics.engagement = (metrics.smile + metrics.attention + (1 - cheekPuff)) / 3;
        metrics.composure = 1 - metrics.stress;

        return metrics;
    }

    // ë©´ì ‘ í”¼ë“œë°± ìƒì„± (í•˜ë‚˜ì˜ í”¼ë“œë°±ë§Œ ìš°ì„ ì ìœ¼ë¡œ í‘œì‹œ)
    private generateInterviewFeedback(metrics: any, leftEye: any, rightEye: any, nose: any) {
        const landmarks = {
            leftEye: { x: leftEye.x, y: leftEye.y },
            rightEye: { x: rightEye.x, y: rightEye.y },
            nose: { x: nose.x, y: nose.y },
        };

        // í”¼ë“œë°± ìš°ì„ ìˆœìœ„: ìŠ¤íŠ¸ë ˆìŠ¤ > ì§‘ì¤‘ë„ > ìì‹ ê° > ë¯¸ì†Œ
        // ê°€ì¥ ì¤‘ìš”í•œ í”¼ë“œë°± í•˜ë‚˜ë§Œ ì„ íƒí•˜ì—¬ í‘œì‹œ

        // 1ìˆœìœ„: ìŠ¤íŠ¸ë ˆìŠ¤/ê¸´ì¥ í”¼ë“œë°± (ê°€ì¥ ì¤‘ìš”)
        if (metrics.stress > 0.6) {
            this.onDetection({
                type: 'stress',
                message: 'ê¸´ì¥ì„ í’€ê³  í¸ì•ˆí•œ ë§ˆìŒìœ¼ë¡œ ë‹µë³€í•´ë³´ì„¸ìš”',
                level: 'warning',
                confidence: 1 - metrics.stress,
                landmarks,
                metrics: {
                    stressLevel: metrics.stress,
                    nervousness: metrics.nervousness,
                    relaxationNeeded: true,
                },
            });
            return; // ë‹¤ë¥¸ í”¼ë“œë°±ì€ í‘œì‹œí•˜ì§€ ì•ŠìŒ
        }

        // 2ìˆœìœ„: ì§‘ì¤‘ë„/ì•„ì´ì»¨íƒ í”¼ë“œë°±
        if (metrics.attention < 0.5 || metrics.eyeContact < 0.5) {
            this.onDetection({
                type: 'attention',
                message: 'ë©´ì ‘ê´€ê³¼ì˜ ì•„ì´ì»¨íƒì„ ë” ìœ ì§€í•´ë³´ì„¸ìš”',
                level: 'warning',
                confidence: Math.max(metrics.attention, metrics.eyeContact),
                landmarks,
                metrics: {
                    attentionScore: metrics.attention,
                    eyeContactScore: metrics.eyeContact,
                    focusLevel: 'needs_improvement',
                },
            });
            return; // ë‹¤ë¥¸ í”¼ë“œë°±ì€ í‘œì‹œí•˜ì§€ ì•ŠìŒ
        }

        // 3ìˆœìœ„: ìì‹ ê° í”¼ë“œë°±
        if (metrics.confidence < 0.4) {
            this.onDetection({
                type: 'confidence',
                message: 'ì¢€ ë” ìì‹ ê° ìˆëŠ” í‘œì •ì„ ì§€ì–´ë³´ì„¸ìš”',
                level: 'warning',
                confidence: metrics.confidence,
                landmarks,
                metrics: {
                    confidenceScore: metrics.confidence,
                    smileIntensity: metrics.smile,
                    overallPresence: 'needs_improvement',
                },
            });
            return; // ë‹¤ë¥¸ í”¼ë“œë°±ì€ í‘œì‹œí•˜ì§€ ì•ŠìŒ
        }

        // 4ìˆœìœ„: ê¸ì •ì  í”¼ë“œë°± (ëª¨ë“  ì§€í‘œê°€ ì–‘í˜¸í•  ë•Œë§Œ)
        if (metrics.confidence > 0.7) {
            this.onDetection({
                type: 'confidence',
                message: 'ìì‹ ê° ìˆëŠ” í‘œì •ì´ ì¸ìƒì ì…ë‹ˆë‹¤!',
                level: 'excellent',
                confidence: metrics.confidence,
                landmarks,
                metrics: {
                    confidenceScore: metrics.confidence,
                    smileIntensity: metrics.smile,
                    overallPresence: 'confident',
                },
            });
            return;
        }

        if (metrics.attention > 0.8 && metrics.eyeContact > 0.7) {
            this.onDetection({
                type: 'attention',
                message: 'í›Œë¥­í•œ ì§‘ì¤‘ë ¥ê³¼ ì•„ì´ì»¨íƒì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤',
                level: 'excellent',
                confidence: (metrics.attention + metrics.eyeContact) / 2,
                landmarks,
                metrics: {
                    attentionScore: metrics.attention,
                    eyeContactScore: metrics.eyeContact,
                    focusLevel: 'high',
                },
            });
            return;
        }

        if (metrics.smile > 0.4) {
            this.onDetection({
                type: 'smile',
                message: 'ìì—°ìŠ¤ëŸ¬ìš´ ë¯¸ì†Œê°€ ì¢‹ì€ ì¸ìƒì„ ì¤ë‹ˆë‹¤',
                level: 'good',
                confidence: metrics.smile,
                landmarks,
                metrics: {
                    smileIntensity: metrics.smile,
                    facialExpression: 'positive',
                    warmth: 'high',
                },
            });
            return;
        }
    }

    // ë©”ì¸ ë¶„ì„ í•¨ìˆ˜ (requestVideoFrameCallback ì‚¬ìš©)
    private analyzeFrame() {
        if (!this.isAnalyzing || !this.videoRef.current || !this.canvasRef.current) {
            return;
        }

        const video = this.videoRef.current;
        const canvas = this.canvasRef.current;

        if (video.readyState !== 4 || !this.faceLandmarker) {
            // requestVideoFrameCallback ì‚¬ìš© (ë” ì •í™•í•œ í”„ë ˆì„ ë™ê¸°í™”)
            if ('requestVideoFrameCallback' in video) {
                (video as any).requestVideoFrameCallback(() => this.analyzeFrame());
            } else {
                // í´ë°±: requestAnimationFrame
                this.animationFrameId = requestAnimationFrame(() => this.analyzeFrame());
            }
            return;
        }

        // ìº”ë²„ìŠ¤ í¬ê¸°ë¥¼ ë¹„ë””ì˜¤ì™€ ë§ì¶¤
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        // ìµœì´ˆ í•œë²ˆë§Œ ì›¹ìº  ë°ì´í„° ë¡œê·¸ ì¶œë ¥
        const currentTime = Date.now();
        if (!this.hasLoggedInitialData) {
            this.logWebcamData(video, canvas);
            this.hasLoggedInitialData = true;
            this.lastLogTime = currentTime;
        }

        // ì„±ëŠ¥ ìµœì í™”: 5ì´ˆ ê°„ê²©ìœ¼ë¡œë§Œ ë¶„ì„ ì‹¤í–‰
        const timeSinceLastAnalysis = currentTime - this.lastAnalysisTime;
        if (timeSinceLastAnalysis < this.analysisInterval) {
            // 5ì´ˆ ê°„ê²©ì´ ì§€ë‚˜ì§€ ì•Šì•˜ìœ¼ë©´ ë‹¤ìŒ í”„ë ˆì„ìœ¼ë¡œ
            if ('requestVideoFrameCallback' in video) {
                (video as any).requestVideoFrameCallback(() => this.analyzeFrame());
            } else {
                this.animationFrameId = requestAnimationFrame(() => this.analyzeFrame());
            }
            return;
        }

        try {
            // MediaPipe Face Landmarkerë¡œ ë¹„ë””ì˜¤ í”„ë ˆì„ ë¶„ì„
            const results = this.faceLandmarker.detectForVideo(video, currentTime);

            if (results) {
                this.lastFaceResults = results;
                this.lastDetectionTime = currentTime;
                this.lastAnalysisTime = currentTime; // ë¶„ì„ ì‹œê°„ ì—…ë°ì´íŠ¸
                this.analyzeFaceResults(results);
            }

            // í”„ë ˆì„ ì „ì†¡ ë¡œê·¸ëŠ” ì œê±° (ë„ˆë¬´ ë§ì€ ë¡œê·¸ ë°©ì§€)
        } catch (error) {
            console.error('âŒ Face Landmarker ê°ì§€ ì˜¤ë¥˜:', error);
        }

        // ë‹¤ìŒ í”„ë ˆì„ ë¶„ì„ ì˜ˆì•½
        if ('requestVideoFrameCallback' in video) {
            (video as any).requestVideoFrameCallback(() => this.analyzeFrame());
        } else {
            this.animationFrameId = requestAnimationFrame(() => this.analyzeFrame());
        }
    }

    // ì›¹ìº  ë°ì´í„° ë¡œê·¸ ì¶œë ¥
    private logWebcamData(video: HTMLVideoElement, canvas: HTMLCanvasElement) {
        const stream = video.srcObject as MediaStream;
        const tracks = stream?.getTracks() || [];

        console.log('ğŸ“Š MediaPipe Tasks Vision ì›¹ìº  ë°ì´í„° (ìµœì´ˆ 1íšŒ):', {
            timestamp: new Date().toISOString(),
            videoInfo: {
                width: video.videoWidth,
                height: video.videoHeight,
                currentTime: video.currentTime,
                duration: video.duration,
                readyState: video.readyState,
                paused: video.paused,
                muted: video.muted,
                volume: video.volume,
            },
            canvasInfo: {
                width: canvas.width,
                height: canvas.height,
            },
            streamInfo: {
                id: stream?.id,
                active: stream?.active,
                tracksCount: tracks.length,
                tracks: tracks.map((track) => ({
                    kind: track.kind,
                    label: track.label,
                    enabled: track.enabled,
                    readyState: track.readyState,
                    muted: track.muted,
                    settings: track.getSettings(),
                    constraints: track.getConstraints(),
                })),
            },
            mediaPipeResults: {
                faceLandmarker: this.lastFaceResults
                    ? {
                          facesCount: this.lastFaceResults.faceLandmarks?.length || 0,
                          blendshapesCount: this.lastFaceResults.faceBlendshapes?.length || 0,
                          hasResults: true,
                      }
                    : { hasResults: false },
            },
            performanceInfo: {
                frameRate: '5ì´ˆ ê°„ê²© ë¶„ì„ ì¤‘ (ì„±ëŠ¥ ìµœì í™”)',
                memoryUsage: (performance as any).memory
                    ? {
                          used:
                              Math.round((performance as any).memory.usedJSHeapSize / 1024 / 1024) +
                              'MB',
                          total:
                              Math.round(
                                  (performance as any).memory.totalJSHeapSize / 1024 / 1024,
                              ) + 'MB',
                          limit:
                              Math.round(
                                  (performance as any).memory.jsHeapSizeLimit / 1024 / 1024,
                              ) + 'MB',
                      }
                    : 'N/A',
            },
            analysisStatus: {
                isAnalyzing: this.isAnalyzing,
                faceLandmarkerReady: !!this.faceLandmarker,
                hasLoggedInitialData: this.hasLoggedInitialData,
                initialLogTime: new Date(this.lastLogTime).toISOString(),
            },
        });
    }

    // ë¶„ì„ ì‹œì‘
    public async startAnalysis() {
        if (this.isAnalyzing) return;

        try {
            // MediaPipe Tasks Vision ëª¨ë¸ ì´ˆê¸°í™”
            await this.initializeModels();

            // ëª¨ë¸ì´ ì¤€ë¹„ë  ë•Œê¹Œì§€ ì ì‹œ ëŒ€ê¸°
            await new Promise((resolve) => setTimeout(resolve, 1000));

            this.isAnalyzing = true;
            this.lastDetectionTime = Date.now();
            this.lastAnalysisTime = Date.now();
            console.log('ğŸ¯ MediaPipe Tasks Vision ë¶„ì„ ì‹œì‘ (5ì´ˆ ê°„ê²©)');
            this.analyzeFrame();
        } catch (error) {
            console.error('âŒ MediaPipe Tasks Vision ë¶„ì„ ì‹œì‘ ì‹¤íŒ¨:', error);
            throw error;
        }
    }

    // ë¶„ì„ ì¤‘ì§€
    public stopAnalysis() {
        this.isAnalyzing = false;
        if (this.animationFrameId) {
            cancelAnimationFrame(this.animationFrameId);
            this.animationFrameId = null;
        }
        console.log('â¹ï¸ MediaPipe Tasks Vision ë¶„ì„ ì¤‘ì§€');
    }

    // ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    public dispose() {
        console.log('ğŸ§¹ MediaPipe Tasks Vision ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹œì‘...');
        this.stopAnalysis();

        if (this.faceLandmarker) {
            console.log('ğŸ”„ Face Landmarker ì •ë¦¬ ì¤‘...');
            this.faceLandmarker.close();
            this.faceLandmarker = null;
        }

        if (this.vision) {
            this.vision = null;
        }

        // ì´ˆê¸°í™” ìƒíƒœ ë¦¬ì…‹
        this.isInitialized = false;
        console.log('âœ… MediaPipe Tasks Vision ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ');
    }
}
