'use client';

import { useEffect, useMemo, useCallback } from 'react';
import { CloseOutlined, LeftOutlined } from '@ant-design/icons';
import { useCanvasStore } from '../_stores/useCanvasStore';
import { useRecordingStore } from '../_stores/useRecordingStore';
import { useAudioPlayer } from '../_hooks/useAudioPlayer';
import { useAudioMetadata } from '../_hooks/useAudioMetadata';
import { useSessionData } from '../_hooks/useSessionData';
import { useDragPosition } from '../_hooks/useDragPosition';
import TranscriptList from './TranscriptList';
import RecordingList from './RecordingList';
import { ChatSession, SpeakerSegment, TranscriptItem } from '@/apis/Recording-api';

export type RecordingItem = {
    id: string;
    title: string;
    durationSec: number;
    createdAt: string;
};

export function RecordingListPopup() {
    // ìŠ¤í† ì–´ì—ì„œ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
    const isOpen = useCanvasStore((s) => s.isRecordingListOpen);
    const setOpen = useCanvasStore((s) => s.setRecordingListOpen);
    const { selectedRecording, setSelectedRecording, isLoadingAudio, setIsLoadingAudio } =
        useRecordingStore();

    // ì»¤ìŠ¤í…€ í›…ë“¤
    const { pos, handleMouseDown } = useDragPosition();
    const { sessions, loading, error, fetchSessionMessages, loadMore, setSessions } =
        useSessionData('default-canvas-uuid');
    const { loadAudioMetadata } = useAudioMetadata();

    // ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ í›…
    const {
        playingSegment,
        currentSession,
        currentSegment,
        currentTime,
        duration,
        isPlaying,
        isFullSessionMode,
        audioRef,
        playSegment,
        stopAudio,
        handleTimeUpdate,
        handleAudioEnd,
        getAudioSources,
        setCurrentSession,
        setPlayingSegment,
        setCurrentSegment,
        setIsFullSessionMode,
        setIsPlaying,
        setCurrentTime,
        setDuration,
    } = useAudioPlayer();

    // ì˜¤ë””ì˜¤ ë¡œë”© í•¨ìˆ˜ (useAudioLoading í›… ëŒ€ì‹  ì§ì ‘ êµ¬í˜„)
    const loadAudioWithDuration = useCallback(
        async (audioUrl: string, session: ChatSession) => {
            setIsLoadingAudio(true);
            try {
                const audioDuration = await loadAudioMetadata(audioUrl);
                setDuration(audioDuration);

                if (audioRef.current) {
                    audioRef.current.src = audioUrl;
                    audioRef.current.preload = 'auto';
                    audioRef.current.load();
                }

                return audioDuration;
            } catch (error) {
                console.warn('Failed to load audio metadata:', error);
                const fallbackDuration = Math.max(...session.segments.map((s) => s.endTime));
                setDuration(fallbackDuration);
                return fallbackDuration;
            } finally {
                setIsLoadingAudio(false);
            }
        },
        [loadAudioMetadata, setIsLoadingAudio, setDuration, audioRef],
    );

    // ë°ì´í„° ë¡œë”©
    useEffect(() => {
        if (isOpen) {
            const loadData = async () => {
                try {
                    const sessions = await fetchSessionMessages(1);
                    setSessions(sessions);
                } catch (error) {
                    console.error('Failed to load sessions:', error);
                }
            };
            loadData();
        }
    }, [isOpen, fetchSessionMessages, setSessions]);

    // ì„¸ì…˜ ë¡œë”© ìµœì í™”
    useEffect(() => {
        if (selectedRecording && sessions.length > 0) {
            const session = sessions.find((s) => `rec-${s.sessionIdx}` === selectedRecording.id);
            if (session) {
                setCurrentSession(session as unknown as ChatSession);
                setPlayingSegment(session.segments[0]);
                setCurrentSegment(session.segments[0]);
                setIsFullSessionMode(true);
                setCurrentTime(0);

                const audioUrl = session.segments[0]?.audioUrl;
                if (audioUrl) {
                    loadAudioWithDuration(audioUrl, session as unknown as ChatSession);
                }
            }
        }
    }, [
        selectedRecording,
        sessions,
        setCurrentSession,
        setPlayingSegment,
        setCurrentSegment,
        setIsFullSessionMode,
        setCurrentTime,
        loadAudioWithDuration,
    ]);

    const getTotalDuration = (session: ChatSession): number => {
        if (!session.segments || session.segments.length === 0) return 0;

        // audioDurationì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ì˜ endTime ì‚¬ìš©
        if (session.audioDuration && session.audioDuration > 0) {
            return session.audioDuration;
        }

        const lastSegment = session.segments[session.segments.length - 1];
        return lastSegment ? lastSegment.endTime : 0;
    };

    const items = useMemo<RecordingItem[]>(() => {
        return sessions.map((session) => ({
            id: `rec-${session.sessionIdx}`,
            title: `ìŒì„± ë©”ëª¨ ${session.segmentIndex}`,
            durationSec: getTotalDuration(session), // ğŸ†• íƒ€ì… ìºìŠ¤íŒ… ì œê±°
            createdAt: new Date(session.timestamp).toLocaleString(),
        }));
    }, [sessions]);

    const transcripts = useMemo<TranscriptItem[]>(() => {
        if (!selectedRecording) return [];

        const session = sessions.find((s) => `rec-${s.sessionIdx}` === selectedRecording.id);
        if (!session) return [];

        return session.segments.map((seg, idx) => ({
            id: `${selectedRecording.id}-line-${idx + 1}`,
            speaker: seg.speakerTag === 0 ? 'ë©˜í† ' : 'ë©˜í‹°',
            timeSec: seg.startTime,
            text: seg.textContent,
            segment: seg,
            session: session, // ï¿½ï¿½ íƒ€ì… ìºìŠ¤íŒ… ì œê±°
        }));
    }, [selectedRecording, sessions]);

    //  í•¸ë“¤ëŸ¬ë“¤
    const handleSegmentClick = useCallback(
        (segment: SpeakerSegment, session: ChatSession) => {
            if (isFullSessionMode && audioRef.current) {
                audioRef.current.currentTime = segment.startTime;
                setPlayingSegment(segment);
                setCurrentSegment(segment);
            } else {
                playSegment(segment, session);
            }
        },
        [isFullSessionMode, playSegment, setPlayingSegment, setCurrentSegment],
    );

    const handlePlayPause = useCallback(async () => {
        if (audioRef.current) {
            try {
                if (audioRef.current.paused) {
                    if (duration === 0) {
                        await new Promise((resolve) => setTimeout(resolve, 100));
                    }
                    await audioRef.current.play();
                    setIsPlaying(true);
                } else {
                    audioRef.current.pause();
                    setIsPlaying(false);
                }
            } catch (error) {
                if (error instanceof Error && error.name !== 'AbortError') {
                    console.error('Audio play/pause error:', error);
                }
            }
        }
    }, [audioRef, duration, setIsPlaying]);

    const handleBack = useCallback(() => {
        setSelectedRecording(null);
        stopAudio();
    }, [setSelectedRecording, stopAudio]);

    const handleClose = useCallback(() => {
        setOpen(false);
        stopAudio();
    }, [setOpen, stopAudio]);

    if (!isOpen) return null;

    return (
        <>
            {/* ìˆ¨ê²¨ì§„ ì˜¤ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ */}
            {currentSession && (
                <audio
                    ref={audioRef}
                    onTimeUpdate={handleTimeUpdate}
                    onEnded={handleAudioEnd}
                    className='hidden'
                    controls={false}
                    preload='none'
                    muted={false}
                >
                    {getAudioSources(currentSession.segments[0]?.audioUrl || '').map(
                        (source, index) => (
                            <source key={index} src={source.src} type={source.type} />
                        ),
                    )}
                </audio>
            )}

            {/* ë©”ì¸ íŒì—… */}
            <div
                className='fixed z-[50]'
                style={{ left: pos.x, top: pos.y }}
                role='dialog'
                aria-modal='false'
                aria-label='ë…¹ìŒ ëª©ë¡'
            >
                <div className='w-[380px] h-[400px] bg-white rounded-xl shadow-[0_8px_24px_rgba(0,0,0,0.2)] border border-slate-200 overflow-hidden flex flex-col'>
                    {/* í—¤ë” */}
                    <div
                        className='h-10 px-2 flex items-center justify-between bg-slate-50 border-b border-slate-200 cursor-move select-none flex-shrink-0'
                        onMouseDown={handleMouseDown}
                    >
                        <div className='flex items-center gap-1'>
                            {selectedRecording && (
                                <button
                                    aria-label='ë’¤ë¡œ'
                                    className='p-1 rounded hover:bg-slate-200 cursor-pointer'
                                    onClick={handleBack}
                                >
                                    <LeftOutlined style={{ fontSize: 14, color: '#334155' }} />
                                </button>
                            )}
                            <span className='text-sm font-medium text-slate-700'>
                                {selectedRecording
                                    ? `${selectedRecording.title} â€¢ STT íƒ€ì„ë¼ì¸`
                                    : 'ë…¹ìŒ ëª©ë¡'}
                            </span>
                            {isLoadingAudio && (
                                <div className='ml-2 w-4 h-4 border-2 border-blue-500 border-t-transparent rounded-full animate-spin' />
                            )}
                        </div>
                        <button
                            aria-label='ë‹«ê¸°'
                            className='p-1 rounded hover:bg-slate-200'
                            onClick={handleClose}
                        >
                            <CloseOutlined style={{ fontSize: 14, color: '#334155' }} />
                        </button>
                    </div>

                    {/* ì½˜í…ì¸  ì˜ì—­ */}
                    <div className='flex-1 overflow-hidden flex flex-col min-h-0'>
                        {selectedRecording ? (
                            <TranscriptList
                                transcripts={transcripts}
                                playingSegment={playingSegment}
                                onPlaySegment={handleSegmentClick}
                                isFullSessionMode={isFullSessionMode}
                                audioRef={audioRef}
                                currentSegment={currentSegment}
                                currentSession={currentSession as ChatSession}
                                currentTime={currentTime}
                                duration={duration}
                                isPlaying={isPlaying}
                                onPlayPause={handlePlayPause}
                                onClose={stopAudio}
                            />
                        ) : (
                            <RecordingList
                                items={items}
                                loading={loading}
                                onRecordingClick={() => {}}
                                onSelectItem={setSelectedRecording}
                                onLoadMore={loadMore}
                            />
                        )}
                    </div>
                </div>
            </div>
        </>
    );
}
